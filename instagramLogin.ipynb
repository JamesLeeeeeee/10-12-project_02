{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "381b9d4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-1091ad2cf5c8>:43: DeprecationWarning: use options instead of chrome_options\n",
      "  self.driver=webdriver.Chrome(chrome_options=chrome_options,executable_path=path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "from random_user_agent.params import SoftwareName, OperatingSystem\n",
    "from random_user_agent.user_agent import UserAgent\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# from eunjeon import Mecab\n",
    "import unicodedata\n",
    "import pyodbc\n",
    "import re\n",
    "import collections\n",
    "class IG_Bot:\n",
    "    '''creating a Bot that acts like me.'''\n",
    "    \n",
    "    def __init__(self, username, password):\n",
    "        software_names= [SoftwareName.CHROME.value]\n",
    "        operating_systems=[OperatingSystem.WINDOWS.value]\n",
    "        \n",
    "        #Randomized User ID\n",
    "        user_agent_rotator= UserAgent(software_name = software_names,\n",
    "                                     operating_systems=operating_systems,\n",
    "                                     limit=100)\n",
    "        user_agent= user_agent_rotator.get_random_user_agent()\n",
    "        chrome_options=Options()\n",
    "#         chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--no-sendbox\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "        path='c:\\python_temp\\chromedriver.exe'\n",
    "        \n",
    "        cookies_file_path='c:\\IG\\cookies.json'\n",
    "        cookie_websites=['https://instagram.com']\n",
    "        self.cookies_file_path= cookies_file_path\n",
    "        self.cookie_websites= cookie_websites\n",
    "        self.driver=webdriver.Chrome(chrome_options=chrome_options,executable_path=path)\n",
    "        \n",
    "        self.driver.get('https://instagram.com')\n",
    "        \n",
    "        time.sleep(1.5)\n",
    "\n",
    "        try:\n",
    "            cookies=json.load(open(self.cookies_file_path,'rb'))\n",
    "            for website in self.cookie_websites:\n",
    "                for cookie in cookies:\n",
    "                    self.driver.add_cookie(cookie)\n",
    "                self.driver.refresh()\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "       \n",
    "    def loading(self,xpath):\n",
    "        '''Wait Loading Until presence'''\n",
    "        WebDriverWait(self.driver,10).until(EC.presence_of_element_located((By.XPATH,xpath)))\n",
    "    \n",
    "    def save_cookies(self):\n",
    "        '''Save cookie'''\n",
    "        json.dump(self.driver.get_cookies(),open('c:\\IG\\cookies.json','w'))\n",
    "    \n",
    "    def load_cookies(self):\n",
    "        '''Load cookies into browser'''\n",
    "        cookies= json.load(open('cookies.json','rb'))\n",
    "        for cookie in cookies:\n",
    "            self.driver.add_cookie(cookie)\n",
    "    \n",
    "    def login(self):\n",
    "        '''Login to Instagram'''\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('//*[@id=\"loginForm\"]/div/div[1]/div/label/input').send_keys(username)\n",
    "            self.driver.find_element_by_xpath('//*[@id=\"loginForm\"]/div/div[2]/div/label/input').send_keys(password)\n",
    "            self.loading('//*[@id=\"loginForm\"]/div/div[3]')\n",
    "            time.sleep(0.5)\n",
    "            self.driver.find_element_by_xpath('//*[@id=\"loginForm\"]/div/div[3]').click()\n",
    "            self.loading('//*[@id=\"react-root\"]/section/main/div/div/div/div/button')\n",
    "            self.driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/div/div/div/button').click()\n",
    "            self.loading('/html/body/div[5]/div/div/div/div[3]/button[2]')\n",
    "            self.driver.find_element_by_xpath('/html/body/div[5]/div/div/div/div[3]/button[2]').click()\n",
    "        except:\n",
    "            self.loading('/html/body/div[5]/div/div/div/div[3]/button[2]')\n",
    "            self.driver.find_element_by_xpath('/html/body/div[5]/div/div/div/div[3]/button[2]').click()\n",
    "\n",
    "'''run the Crawler'''           \n",
    "class Crawler(IG_Bot):\n",
    "    global insta_dict\n",
    "    insta_dict = {'img':[],\n",
    "                  'id':[],\n",
    "                  'date': [],\n",
    "                  'like': [],\n",
    "                  'text': [],\n",
    "                  'hashtag':[]}\n",
    "    def run(self):\n",
    "        continue_=True\n",
    "        count=0\n",
    "        query=input('검색어를 입력하시오. > ') \n",
    "        self.driver.get('https://www.instagram.com/explore/tags/'+query)\n",
    "        \n",
    "        s_time=time.time()\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('/html/body/div[5]/div/div/div/div[3]/button[2]').click()\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(0.5)\n",
    "        self.loading('//*[@id=\"react-root\"]/section/main/article/div[1]/div/div/div[1]/div[1]/a/div[1]/div[2]')\n",
    "        self.driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/article/div[1]/div/div/div[1]/div[1]/a/div[1]/div[2]').click()\n",
    "        while count<2000:\n",
    "            self.crawl()\n",
    "            \n",
    "#Acting like person by random\n",
    "            time.sleep(random.randrange(0,5))\n",
    "            try:\n",
    "                self.driver.find_element_by_css_selector('a._65Bje').click()\n",
    "            except:\n",
    "                continue_=False\n",
    "            count+=1\n",
    "            time.sleep(2)\n",
    "            if continue_==False:\n",
    "                break\n",
    "        print(len(insta_dict['img']))\n",
    "        print(len(insta_dict['id']))\n",
    "        print(len(insta_dict['date']))\n",
    "        print(len(insta_dict['like']))\n",
    "        print(len(insta_dict['text']))\n",
    "        print(len(insta_dict['hashtag']))\n",
    "        print(insta_dict)\n",
    "        e_time=time.time()\n",
    "        (f'{e_time-s_time}초 걸렸습니다.')    \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    def crawl(self):\n",
    "        \n",
    "        ## 이미지 수집\n",
    "        time.sleep(0.8)\n",
    "        try:       \n",
    "            srcs=self.driver.find_element_by_css_selector('video.tWeC1')\n",
    "            src=srcs.get_attribute('poster')\n",
    "            insta_dirct['img'].append(src)\n",
    "        except:\n",
    "            src=self.driver.find_element_by_css_selector('img.FFVAD')\n",
    "            src=src.get_attribute('src')\n",
    "            insta_dict['img'].append(src)\n",
    "            \n",
    "        ## id 정보 수집\n",
    "        try:\n",
    "            info_id = self.driver.find_element_by_css_selector('h2._6lAjh').text\n",
    "            insta_dict['id'].append(info_id)\n",
    "        except:\n",
    "            try:          \n",
    "                info_id = self.driver.find_element_by_css_selector('div.C4VMK').text.split()[0]\n",
    "                insta_dict['id'].append(info_id)\n",
    "            except:  \n",
    "                info_id = self.driver.find_element_by_css_selector('div.e1e1d').text\n",
    "                insta_dict['id'].append(info_id)\n",
    "            \n",
    "\n",
    "\n",
    "        ## 시간정보 수집 \n",
    "        uploadTime=self.driver.find_element_by_css_selector('time._1o9PC')\n",
    "        time_info=uploadTime.get_attribute('datetime')[:19]\n",
    "        insta_dict['date'].append(time_info)\n",
    "        \n",
    "\n",
    "        ## like 정보 수집\n",
    "        try:\n",
    "            check=self.driver.find_element_by_css_selector('span.vcOH2').text\n",
    "            check=re.sub(r'[^0-9]', '', check)\n",
    "            insta_dict['like'].append(check)\n",
    "        except:\n",
    "            if '가장 먼저' in self.driver.find_element_by_css_selector('div.Nm9Fw').text:\n",
    "                like=0\n",
    "            elif '여러 명' in self.driver.find_element_by_css_selector('div.Nm9Fw').text:\n",
    "                id=[]\n",
    "                self.driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div[2]/section[2]/div/div[2]/a[2]').click()\n",
    "                time.sleep(1)\n",
    "                while True:\n",
    "                    last_height =self.driver.find_element_by_xpath('/html/body/div[7]/div/div/div[3]/div/div/div/div/div/div/span/a').location\n",
    "\n",
    "                    c=self.driver.find_elements_by_xpath('/html/body/div[7]/div/div/div[3]/div/div/div/div/div/div/span/a')\n",
    "\n",
    "                    for i in c:  \n",
    "                        if i.text not in id:\n",
    "                            id.append(i.text)     \n",
    "                        else:\n",
    "                            pass\n",
    "                    self.driver.find_element_by_css_selector('div._1XyCr').click()\n",
    "                    self.driver.find_element_by_css_selector('body').send_keys(Keys.PAGE_DOWN)\n",
    "                    self.driver.find_element_by_css_selector('body').send_keys(Keys.PAGE_DOWN)\n",
    "                    self.driver.find_element_by_css_selector('body').send_keys(Keys.PAGE_DOWN)\n",
    "                    time.sleep(1)\n",
    "                    new_height =self.driver.find_element_by_xpath('/html/body/div[7]/div/div/div[3]/div/div/div/div/div/div/span/a').location\n",
    "\n",
    "                    if last_height==new_height:\n",
    "                        self.driver.find_element_by_xpath('/html/body/div[7]/div/div/div[1]/div/div[2]/button').click()\n",
    "                        break\n",
    "                like=len(id)\n",
    "            else:\n",
    "                like=self.driver.find_element_by_css_selector('a.zV_Nj')\n",
    "                like = re.sub(r'[^0-9]', '', like.text)\n",
    "            insta_dict['like'].append(like)\n",
    "           \n",
    "\n",
    "                \n",
    "\n",
    "        ##text 정보수집\n",
    "        raw_info = self.driver.find_element_by_css_selector('div.C4VMK').text.split()\n",
    "        raw_info = raw_info[1:len(raw_info)-1]\n",
    "        text=[]\n",
    "        cleantext=[]\n",
    "        for i in raw_info:\n",
    "            if '#' in i:\n",
    "                pass\n",
    "            else:\n",
    "                text.append(i)\n",
    "        clean_text = ' '.join(text)\n",
    "        cleantext.append(clean_text)\n",
    "        insta_dict['text'].append(cleantext)\n",
    "\n",
    "\n",
    "\n",
    "        ##hashtag 수집\n",
    "        raw_tags = self.driver.find_elements_by_css_selector('a.xil3i')\n",
    "        hash_tag = []\n",
    "        for i in raw_tags:\n",
    "            hash_tag.append(i.text)\n",
    "        insta_dict['hashtag'].append(hash_tag)\n",
    "        \n",
    "        \n",
    "        '''c드라이브에 IG폴더 만들고 secret.txt 파일에 윗줄에 아이디 2번째줄에 비밀번호 입력'''    \n",
    "if __name__=='__main__':\n",
    "    \"Main (runs through classes)\"\n",
    "    data=pd.read_csv('c:\\IG\\secret.txt',header=None)\n",
    "    username=data.iloc[0][0]\n",
    "    password=data.iloc[1][0]\n",
    "    \n",
    "    '''처음실행하고 쿠키저장'''\n",
    "def first_login():     \n",
    "    '''Check login to instagram and save cookies'''\n",
    "    bot=IG_Bot(username,password)\n",
    "    bot.login()\n",
    "    bot.save_cookies()\n",
    "\n",
    "    '''쿠키저장 후 크롤러 가동하기'''\n",
    "def run_():\n",
    "    # '''Crawler'''\n",
    "    bot=Crawler(username,password)\n",
    "    bot.run()\n",
    "\n",
    "    '''아래 셀은 쿠기 저장 예시'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "204d8486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://scontent-gmp1-1.cdninstagram.com/v/t51.2885-15/e35/s1080x1080/239218352_335498761650611_1251356593086644312_n.jpg?_nc_ht=scontent-gmp1-1.cdninstagram.com&_nc_cat=111&_nc_ohc=G78EYJ1SFPMAX_B6Pku&edm=AP_V10EBAAAA&ccb=7-4&oh=76b23c271d1ea87146c2781573ac94fe&oe=616D2144&_nc_sid=4f375e\n",
      "['hello_storylibrary']\n",
      "\n",
      "2021년 8월 20일\n",
      "[Timestamp('2021-08-20 00:00:00+0000', tz='UTC')]\n",
      "\n",
      "26\n",
      "\n",
      "[\"[스토리라이브러리만의 특별한 영화 추천, 스라의 빛✨소개] 🎬 너무 좋아서 벽치다가 무너져서 🎬 옆집 만날 장르?! 🎬 말이 필요없는 망작?! 🎬 꿈에 나올것 같았던 영화?! 🎬 간단하게 보기 좋은 영화?! 🎬 꿈인지 현실인지 헷갈리는 영화?! 스라러 재영이 만들어준 영화 추천 큐레이션 게시판, '스라의 빛' 반응이 핫해요! 이미 있는 영화 장르를 제외하고 새로운 장르와 장르에 어울리는 영화를 추천하는 게시판이에요. 게시판이 생긴지 한달도 되지 않아서 어느새 빼곡히 추천 장르, 영화로 가득찼어요. 하루 하루 스라러들이 슬쩍 남겨주고 간 흔적을 읽어보는 재미가 쏠쏠해요. 새로운 영화를 살펴보며 낯선 영감을 만나고 싶다면 스라로 놀러오세요! 오늘도 스토리라이브러리 문 활-짝! 저녁 6시까지 문을 열어둘께요. 9월부터는 수, 목, 금요일은 오후 5시부터 저녁 9시까지, 주말엔 오후 12시부터 6시까지 문을 열어요! 놀러오고 싶다면 프로필 링크를 클릭👆\"]\n",
      "\n",
      "['#스토리라이브러리', '#스라', '#스라러', '#스라의빛', '#영화', '#영화추천', '#장르', '#장르추천', '#1219세전용작업실', '#혜화역2번출구']\n"
     ]
    }
   ],
   "source": [
    "'''예시 아래 결과창'''\n",
    "\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "def crawl(self):\n",
    "    insta_dict = {'img':[],\n",
    "                    'id':[],\n",
    "                  'date': [],\n",
    "                  'like': [],\n",
    "                  'text': [],\n",
    "                  'hashtag':[]}\n",
    "    ## 이미지 수집\n",
    "\n",
    "    try:\n",
    "        srcs=driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[1]/div/div/div/div/div/video')\n",
    "        src=srcs.get_attribute('poster')\n",
    "        insta_dirct['img'].append(src)\n",
    "    except:\n",
    "        src=driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[1]/div/div[1]/div[2]/div/div/div/ul/li/div/div/div/div/img')\n",
    "        src=src.get_attribute('src')\n",
    "        insta_dict['img'].append(src)\n",
    "    ## id 정보 수집\n",
    "    try:\n",
    "        info_id = driver.find_element_by_css_selector('h2._6lAjh').text\n",
    "        insta_dict['id'].append(info_id)\n",
    "    except:\n",
    "        info_id = driver.find_element_by_css_selector('div.C4VMK').text.split()[0]\n",
    "        insta_dict['id'].append(info_id)\n",
    "    print(insta_dict['id'])\n",
    "    print()\n",
    "\n",
    "\n",
    "    ## 시간정보 수집 \n",
    "    upload_time=driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div[2]/div[2]/a/time')\n",
    "    print(upload_time.get_attribute('title'))\n",
    "    time_raw = driver.find_element_by_css_selector('time.FH9sR.Nzb55')\n",
    "    time_info = pd.to_datetime(time_raw.get_attribute('datetime')).normalize()\n",
    "    insta_dict['date'].append(time_info)\n",
    "    print(insta_dict['date'])\n",
    "    print()\n",
    "\n",
    "    ## like 정보 수집\n",
    "    try:\n",
    "        check=driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div[2]/section[2]/div/span/span')\n",
    "        \n",
    "    except:\n",
    "        try:\n",
    "            like=driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div[2]/section[2]/div/div/a/span')\n",
    "            insta_dict['like'].append(like)\n",
    "            \n",
    "        except:\n",
    "            id=[]\n",
    "            driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div[2]/section[2]/div/div[2]/a[2]').click()\n",
    "            while True:\n",
    "                last_height =driver.find_element_by_xpath('/html/body/div[7]/div/div/div[3]/div/div/div/div/div/div/span/a').location\n",
    "\n",
    "                c=driver.find_elements_by_xpath('/html/body/div[7]/div/div/div[3]/div/div/div/div/div/div/span/a')\n",
    "\n",
    "                for i in c:  \n",
    "                    if i.text not in id:\n",
    "                        id.append(i.text)     \n",
    "                    else:\n",
    "                        pass\n",
    "                driver.find_element_by_css_selector('div._1XyCr').click()\n",
    "                driver.find_element_by_css_selector('body').send_keys(Keys.PAGE_DOWN)\n",
    "                driver.find_element_by_css_selector('body').send_keys(Keys.PAGE_DOWN)\n",
    "                driver.find_element_by_css_selector('body').send_keys(Keys.PAGE_DOWN)\n",
    "                time.sleep(1)\n",
    "                new_height =driver.find_element_by_xpath('/html/body/div[7]/div/div/div[3]/div/div/div/div/div/div/span/a').location\n",
    "\n",
    "                if last_height==new_height:\n",
    "                    driver.find_element_by_xpath('/html/body/div[7]/div/div/div[1]/div/div[2]/button').click()\n",
    "                    break\n",
    "\n",
    "            like=len(id)\n",
    "            insta_dict['like'].append(like)\n",
    "\n",
    "    ##text 정보수집\n",
    "    raw_info = driver.find_element_by_css_selector('div.C4VMK').text.split()\n",
    "    raw_info = raw_info[1:len(raw_info)-1]\n",
    "    text=[]\n",
    "    for i in raw_info:\n",
    "        if '#' in i:\n",
    "            pass\n",
    "        else:\n",
    "            text.append(i)\n",
    "    clean_text = ' '.join(text)\n",
    "    text.append(clean_text)\n",
    "    insta_dict['text'].append(text)\n",
    "\n",
    "\n",
    "\n",
    "    ##hashtag 수집\n",
    "    raw_tags = driver.find_elements_by_css_selector('a.xil3i')\n",
    "    hash_tag = []\n",
    "    for i in raw_tags:\n",
    "        hash_tag.append(i.text)\n",
    "    insta_dict['hashtag'].append(hash_tag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
