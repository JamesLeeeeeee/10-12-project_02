{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "381b9d4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-18b670846fdc>:46: DeprecationWarning: use options instead of chrome_options\n",
      "  self.driver=webdriver.Chrome(chrome_options=chrome_options,executable_path=path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색어를 입력하시오. > 수서역서래향\n",
      "이미지 저장 개수 :3개\n",
      "id 저장 개수 :3개\n",
      "날짜 저장 개수 :3개\n",
      "좋아요 저장 개수 :3개\n",
      "텍스트 저장 개수 :3개\n",
      "해쉬태그 저장 개수 :3개\n",
      "{'img': ['https://scontent-ssn1-1.cdninstagram.com/v/t51.2885-15/e35/175966776_454718082415841_4059414997000957574_n.jpg?_nc_ht=scontent-ssn1-1.cdninstagram.com&_nc_cat=105&_nc_ohc=GsaiVab43qkAX9N6rv_&edm=AP_V10EBAAAA&ccb=7-4&oh=02d718916cd3ff4aed9724d83aa12f6f&oe=61800127&_nc_sid=4f375e', 'https://scontent-ssn1-1.cdninstagram.com/v/t51.2885-15/e35/19367734_1497197323676332_7383667497632792576_n.jpg?_nc_ht=scontent-ssn1-1.cdninstagram.com&_nc_cat=104&_nc_ohc=GH2CSjdaaPMAX9-PhpC&edm=AP_V10EBAAAA&ccb=7-4&oh=48b60a1008639b46f80d55cdd86571ea&oe=61807F60&_nc_sid=4f375e', 'https://scontent-ssn1-1.cdninstagram.com/v/t51.2885-15/e35/19227630_1488905274485936_2528981339223359488_n.jpg?_nc_ht=scontent-ssn1-1.cdninstagram.com&_nc_cat=108&_nc_ohc=yld71RURviEAX-PKZGf&tn=VyDqJwjQWkdIuwcY&edm=AP_V10EBAAAA&ccb=7-4&oh=7fbec606ef73da6a99caeb3791fd4bde&oe=61819841&_nc_sid=4f375e'], 'id': ['rani.0505', 'jinazzaaang', 'jinazzaaang'], 'date': ['2021-04-19T22:48:17', '2017-06-23T12:19:43', '2017-06-16T14:22:08'], 'like': ['92', '10', '5'], 'text': [['갑자기 중식이 훅 땡기는 날 친구들이랑 오붓하게 수서동 서래향 룸 잡아서 폭풍 먹방! 프라이빗하게 먹으니 좋고 오랜만에 중국요리 먹으니 왜 이리 맛있는건지~ 깐풍기, 멘보샤, 탕수육 순삭하고 짜장면에 짬뽕까지! 제대로 잘 먹었다~~'], ['사천갈비요리~♡♡'], ['맛있는 해삼쥬스~^^']], 'hashtag': [['#수서동맛집', '#수서동모임', '#친구랑', '#수서동중식당', '#수서역서래향', '#멘보샤', '#깐풍기', '#수서동중국집', '#수서역중식', '#짜장면', '#짬뽕', '#먹팔', '#먹스타그램', '#중국요리', '#중국집'], ['#수서역맛집', '#맛있는요리', '#수서역서래향', '#나도먹고싶다'], ['#수서역서래향', '#맛있는중식당', '#뷰가좋은룸수서역서래향']]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'아래 셀은 쿠기 저장 예시'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd #자료의 데이터프레임화\n",
    "import random #타임슬립에 랜덤숫자적용\n",
    "import time #타입슬립\n",
    "import json #파일저장\n",
    "#인스타그램 접속\n",
    "from random_user_agent.params import SoftwareName, OperatingSystem \n",
    "from random_user_agent.user_agent import UserAgent\n",
    "#웹드라이버 및 화면조종\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.webdriver.common.by import By #로딩함수에 적용\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# from eunjeon import Mecab\n",
    "import unicodedata #이모티콘\n",
    "# import pyodbc\n",
    "import re #문자분류\n",
    "import collections \n",
    "class IG_Bot:\n",
    "    '''로봇처럼 보이기 방지'''\n",
    "    \n",
    "    def __init__(self, username, password):\n",
    "        software_names= [SoftwareName.CHROME.value]\n",
    "        operating_systems=[OperatingSystem.WINDOWS.value]\n",
    "        \n",
    "        #Randomized User ID\n",
    "        user_agent_rotator= UserAgent(software_name = software_names,\n",
    "                                     operating_systems=operating_systems,\n",
    "                                     limit=100)\n",
    "        user_agent= user_agent_rotator.get_random_user_agent()\n",
    "        chrome_options=Options()\n",
    "#         chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--no-sendbox\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "        path='c:\\python_temp\\chromedriver.exe'\n",
    "        \n",
    "        cookies_file_path='c:\\IG\\cookies.json'\n",
    "        cookie_websites=['https://instagram.com']\n",
    "        self.cookies_file_path= cookies_file_path\n",
    "        self.cookie_websites= cookie_websites\n",
    "        self.driver=webdriver.Chrome(chrome_options=chrome_options,executable_path=path)\n",
    "        \n",
    "        self.driver.get('https://instagram.com')\n",
    "        \n",
    "        time.sleep(1.5)\n",
    "\n",
    "        try:\n",
    "            cookies=json.load(open(self.cookies_file_path,'rb'))\n",
    "            for website in self.cookie_websites:\n",
    "                for cookie in cookies:\n",
    "                    self.driver.add_cookie(cookie)\n",
    "                self.driver.refresh()\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "       \n",
    "    def loading(self,xpath):\n",
    "        '''페이지로딩 기다리기'''\n",
    "        WebDriverWait(self.driver,60).until(EC.presence_of_element_located((By.XPATH,xpath)))\n",
    "    \n",
    "    def save_cookies(self):\n",
    "        '''쿠키저장'''\n",
    "        json.dump(self.driver.get_cookies(),open('c:\\IG\\cookies.json','w'))\n",
    "    \n",
    "    def load_cookies(self):\n",
    "        '''쿠키로드'''\n",
    "        cookies= json.load(open('cookies.json','rb'))\n",
    "        for cookie in cookies:\n",
    "            self.driver.add_cookie(cookie)\n",
    "    \n",
    "    def login(self):\n",
    "        '''로그인'''\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('//*[@id=\"loginForm\"]/div/div[1]/div/label/input').send_keys(username)\n",
    "            self.driver.find_element_by_xpath('//*[@id=\"loginForm\"]/div/div[2]/div/label/input').send_keys(password)\n",
    "            self.loading('//*[@id=\"loginForm\"]/div/div[3]')\n",
    "            time.sleep(0.5)\n",
    "            self.driver.find_element_by_xpath('//*[@id=\"loginForm\"]/div/div[3]').click()\n",
    "            self.loading('//*[@id=\"react-root\"]/section/main/div/div/div/div/button')\n",
    "            self.driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/div/div/div/button').click()\n",
    "            self.loading('/html/body/div[5]/div/div/div/div[3]/button[2]')\n",
    "            self.driver.find_element_by_xpath('/html/body/div[5]/div/div/div/div[3]/button[2]').click()\n",
    "        except:\n",
    "            self.loading('/html/body/div[5]/div/div/div/div[3]/button[2]')\n",
    "            self.driver.find_element_by_xpath('/html/body/div[5]/div/div/div/div[3]/button[2]').click()\n",
    "\n",
    "'''크롤러'''           \n",
    "class Crawler(IG_Bot):\n",
    "    global insta_dict\n",
    "    insta_dict = {'img':[],\n",
    "                  'id':[],\n",
    "                  'date': [],\n",
    "                  'like': [],\n",
    "                  'text': [],\n",
    "                  'hashtag':[]}\n",
    "    def run(self):\n",
    "        continue_=True\n",
    "        count=0\n",
    "        query=input('검색어를 입력하시오. > ') \n",
    "        self.driver.get('https://www.instagram.com/explore/tags/'+query)\n",
    "        \n",
    "        s_time=time.time()\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('/html/body/div[5]/div/div/div/div[3]/button[2]').click()\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(0.5)\n",
    "        self.loading('//*[@id=\"react-root\"]/section/main/article/div[1]/div/div/div[1]/div[1]/a/div[1]/div[2]')\n",
    "        self.driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/article/div[1]/div/div/div[1]/div[1]/a/div[1]/div[2]').click()\n",
    "        while count<2000:\n",
    "            self.crawl()\n",
    "            \n",
    "                                                #Acting like person by random\n",
    "            time.sleep(random.randrange(0,5))\n",
    "            try:\n",
    "                self.driver.find_element_by_css_selector('div.l8mY4 ').click()\n",
    "            \n",
    "            except:\n",
    "                continue_=False\n",
    "            count+=1\n",
    "            time.sleep(2)\n",
    "            if continue_==False:\n",
    "                break\n",
    "        print('이미지 저장 개수 :{}개'.format(len(insta_dict['img'])))\n",
    "        print('id 저장 개수 :{}개'.format(len(insta_dict['id'])))\n",
    "        print('날짜 저장 개수 :{}개'.format(len(insta_dict['date'])))\n",
    "        print('좋아요 저장 개수 :{}개'.format(len(insta_dict['like'])))\n",
    "        print('텍스트 저장 개수 :{}개'.format(len(insta_dict['text'])))\n",
    "        print('해쉬태그 저장 개수 :{}개'.format(len(insta_dict['hashtag'])))\n",
    "        #예시 10개\n",
    "        if len(insta_dict['img'])>10:\n",
    "            insta_dict['img'][:10]\n",
    "            insta_dict['id'][:10]\n",
    "            insta_dict['date'][:10]\n",
    "            insta_dict['like'][:10]\n",
    "            insta_dict['text'][:10]\n",
    "            insta_dict['hashtag'][:10]\n",
    "        else:\n",
    "            print(insta_dict)\n",
    "        e_time=time.time()\n",
    "        (f'{e_time-s_time}초 걸렸습니다.')    \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "  #페이지 스크랩핑  \n",
    "    def crawl(self):\n",
    "        self.loading('/html/body/div[6]/div[2]/div/article')\n",
    "     \n",
    "        ## 이미지 수집\n",
    "        time.sleep(0.8)\n",
    "        try:       \n",
    "            srcs=self.driver.find_element_by_css_selector('video.tWeCl')\n",
    "            src=srcs.get_attribute('poster')\n",
    "            insta_dict['img'].append(src)\n",
    "        except:\n",
    "            try:\n",
    "                src = self.driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article')\n",
    "                src = src.find_element_by_css_selector(\"img.FFVAD\").get_attribute('src')\n",
    "                insta_dict['img'].append(src)\n",
    "\n",
    "            except:       \n",
    "                src=self.driver.find_element_by_css_selector('div.qF0y9')\n",
    "                src=src.find_element_by_css_selector('img.FFAVD').get_attribute('src')\n",
    "                insta_dict['img'].append(src)\n",
    "\n",
    "        \n",
    "            \n",
    "        ## id 정보 수집\n",
    "        try:\n",
    "            info_id = self.driver.find_element_by_css_selector('h2._6lAjh').text\n",
    "            insta_dict['id'].append(info_id)\n",
    "        except:\n",
    "            try:          \n",
    "                info_id = self.driver.find_element_by_css_selector('div.C4VMK').text.split()[0]\n",
    "                insta_dict['id'].append(info_id)\n",
    "            except:  \n",
    "                info_id = self.driver.find_element_by_css_selector('div.e1e1d').text\n",
    "                insta_dict['id'].append(info_id)\n",
    "            \n",
    "\n",
    "\n",
    "        ## 시간정보 수집 \n",
    "        uploadTime=self.driver.find_element_by_css_selector('time._1o9PC')\n",
    "        time_info=uploadTime.get_attribute('datetime')[:19]\n",
    "        insta_dict['date'].append(time_info)\n",
    "        \n",
    "\n",
    "        ## like 정보 수집\n",
    "        try:\n",
    "            check=self.driver.find_element_by_css_selector('span.vcOH2').text\n",
    "            check=re.sub(r'[^0-9]', '', check)\n",
    "            insta_dict['like'].append(check)\n",
    "        except:\n",
    "            if '가장 먼저' in self.driver.find_element_by_css_selector('div.Nm9Fw').text:\n",
    "                like=0\n",
    "            elif '여러 명' in self.driver.find_element_by_css_selector('div.Nm9Fw').text:\n",
    "                id=[]\n",
    "                self.driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div[2]/section[2]/div/div[2]/a[2]').click()\n",
    "                time.sleep(1)\n",
    "                while True:\n",
    "                    last_height =self.driver.find_element_by_xpath('/html/body/div[7]/div/div/div[3]/div/div/div/div/div/div/span/a').location\n",
    "\n",
    "                    c=self.driver.find_elements_by_xpath('/html/body/div[7]/div/div/div[3]/div/div/div/div/div/div/span/a')\n",
    "\n",
    "                    for i in c:  \n",
    "                        if i.text not in id:\n",
    "                            id.append(i.text)     \n",
    "                        else:\n",
    "                            pass\n",
    "                    action = webdriver.common.action_chains.ActionChains(self.driver)\n",
    "                    el=self.driver.find_element_by_xpath('/html/body/div[7]/div/div/div[3]')\n",
    "                    action.move_to_element_with_offset(el, 300, 10)\n",
    "                    action.click()\n",
    "                    action.perform()\n",
    "                    self.driver.find_element_by_css_selector('body').send_keys(Keys.PAGE_DOWN)\n",
    "                    self.driver.find_element_by_css_selector('body').send_keys(Keys.PAGE_DOWN)\n",
    "                    self.driver.find_element_by_css_selector('body').send_keys(Keys.PAGE_DOWN)\n",
    "                    time.sleep(1)\n",
    "                    new_height =self.driver.find_element_by_xpath('/html/body/div[7]/div/div/div[3]/div/div/div/div/div/div/span/a').location\n",
    "\n",
    "                    if last_height==new_height:\n",
    "                        self.driver.find_element_by_xpath('/html/body/div[7]/div/div/div[1]/div/div[2]/button').click()\n",
    "                        break\n",
    "                like=len(id)\n",
    "            else:\n",
    "                like=self.driver.find_element_by_css_selector('a.zV_Nj')\n",
    "                like = re.sub(r'[^0-9]', '', like.text)\n",
    "            insta_dict['like'].append(like)\n",
    "           \n",
    "\n",
    "                \n",
    "\n",
    "        ##text 정보수집\n",
    "        try:\n",
    "            raw_info = self.driver.find_element_by_css_selector('div.C4VMK').text.split()\n",
    "            raw_info = raw_info[1:len(raw_info)-1]\n",
    "            text=[]\n",
    "            cleantext=[]\n",
    "            for i in raw_info:\n",
    "                if '#' in i:\n",
    "                    pass\n",
    "                else:\n",
    "                    text.append(i)\n",
    "            clean_text = ' '.join(text)\n",
    "            cleantext.append(clean_text)\n",
    "            insta_dict['text'].append(cleantext)\n",
    "        except:\n",
    "            text=[]\n",
    "            insta_dict['text'].append(text)\n",
    "\n",
    "\n",
    "\n",
    "        ##hashtag 수집\n",
    "        raw_tags = self.driver.find_elements_by_css_selector('a.xil3i')\n",
    "        hash_tag = []\n",
    "        for i in raw_tags:\n",
    "            hash_tag.append(i.text)\n",
    "        insta_dict['hashtag'].append(hash_tag)\n",
    "        \n",
    "        \n",
    "        '''c드라이브에 IG폴더 만들고 secret.txt 파일에 윗줄에 아이디 2번째줄에 비밀번호 입력'''    \n",
    "if __name__=='__main__':\n",
    "    \"Main (runs through classes)\"\n",
    "    data=pd.read_csv('c:\\IG\\secret.txt',header=None)\n",
    "    username=data.iloc[0][0]\n",
    "    password=data.iloc[1][0]\n",
    "    \n",
    "    '''처음실행하고 쿠키저장'''\n",
    "def first_login():     \n",
    "    '''Check login to instagram and save cookies'''\n",
    "    bot=IG_Bot(username,password)\n",
    "    bot.login()\n",
    "    bot.save_cookies()\n",
    "\n",
    "    '''쿠키저장 후 크롤러 가동하기'''\n",
    "def run_():\n",
    "    # '''Crawler'''\n",
    "    bot=Crawler(username,password)\n",
    "    bot.run()\n",
    "\n",
    "# first_login()\n",
    "run_()\n",
    "'''아래 셀은 쿠기 저장 예시'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41991d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(insta_dict['img'])  # 추출된 각 항목당 갯수\n",
    "\n",
    "# 폴더 경로 설정 및 json 파일로 저장.\n",
    "with open('c:\\IG\\혜화역1번출구_1927', 'w') as f:\n",
    "    json.dump(insta_dict, f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a62a4031",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\IG\\\\sample.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-4a88dd7c7704>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'c:\\IG\\sample.json'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\IG\\\\sample.json'"
     ]
    }
   ],
   "source": [
    "#json 파일 로드\n",
    "with open('c:\\IG\\sample.json','r') as f:\n",
    "    json_file=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "204d8486",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://scontent-gmp1-1.cdninstagram.com/v/t51.2885-15/e35/s1080x1080/239218352_335498761650611_1251356593086644312_n.jpg?_nc_ht=scontent-gmp1-1.cdninstagram.com&_nc_cat=111&_nc_ohc=G78EYJ1SFPMAX_B6Pku&edm=AP_V10EBAAAA&ccb=7-4&oh=76b23c271d1ea87146c2781573ac94fe&oe=616D2144&_nc_sid=4f375e\n",
      "['hello_storylibrary']\n",
      "\n",
      "2021년 8월 20일\n",
      "[Timestamp('2021-08-20 00:00:00+0000', tz='UTC')]\n",
      "\n",
      "26\n",
      "\n",
      "[\"[스토리라이브러리만의 특별한 영화 추천, 스라의 빛✨소개] 🎬 너무 좋아서 벽치다가 무너져서 🎬 옆집 만날 장르?! 🎬 말이 필요없는 망작?! 🎬 꿈에 나올것 같았던 영화?! 🎬 간단하게 보기 좋은 영화?! 🎬 꿈인지 현실인지 헷갈리는 영화?! 스라러 재영이 만들어준 영화 추천 큐레이션 게시판, '스라의 빛' 반응이 핫해요! 이미 있는 영화 장르를 제외하고 새로운 장르와 장르에 어울리는 영화를 추천하는 게시판이에요. 게시판이 생긴지 한달도 되지 않아서 어느새 빼곡히 추천 장르, 영화로 가득찼어요. 하루 하루 스라러들이 슬쩍 남겨주고 간 흔적을 읽어보는 재미가 쏠쏠해요. 새로운 영화를 살펴보며 낯선 영감을 만나고 싶다면 스라로 놀러오세요! 오늘도 스토리라이브러리 문 활-짝! 저녁 6시까지 문을 열어둘께요. 9월부터는 수, 목, 금요일은 오후 5시부터 저녁 9시까지, 주말엔 오후 12시부터 6시까지 문을 열어요! 놀러오고 싶다면 프로필 링크를 클릭👆\"]\n",
      "\n",
      "['#스토리라이브러리', '#스라', '#스라러', '#스라의빛', '#영화', '#영화추천', '#장르', '#장르추천', '#1219세전용작업실', '#혜화역2번출구']\n"
     ]
    }
   ],
   "source": [
    "'''예시 아래 결과창'''\n",
    "\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "def crawl(self):\n",
    "    insta_dict = {'img':[],\n",
    "                    'id':[],\n",
    "                  'date': [],\n",
    "                  'like': [],\n",
    "                  'text': [],\n",
    "                  'hashtag':[]}\n",
    "    ## 이미지 수집\n",
    "\n",
    "    try:\n",
    "        srcs=driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[1]/div/div/div/div/div/video')\n",
    "        src=srcs.get_attribute('poster')\n",
    "        insta_dirct['img'].append(src)\n",
    "    except:\n",
    "        src=driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[1]/div/div[1]/div[2]/div/div/div/ul/li/div/div/div/div/img')\n",
    "        src=src.get_attribute('src')\n",
    "        insta_dict['img'].append(src)\n",
    "    ## id 정보 수집\n",
    "    try:\n",
    "        info_id = driver.find_element_by_css_selector('h2._6lAjh').text\n",
    "        insta_dict['id'].append(info_id)\n",
    "    except:\n",
    "        info_id = driver.find_element_by_css_selector('div.C4VMK').text.split()[0]\n",
    "        insta_dict['id'].append(info_id)\n",
    "    print(insta_dict['id'])\n",
    "    print()\n",
    "\n",
    "\n",
    "    ## 시간정보 수집 \n",
    "    upload_time=driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div[2]/div[2]/a/time')\n",
    "    print(upload_time.get_attribute('title'))\n",
    "    time_raw = driver.find_element_by_css_selector('time.FH9sR.Nzb55')\n",
    "    time_info = pd.to_datetime(time_raw.get_attribute('datetime')).normalize()\n",
    "    insta_dict['date'].append(time_info)\n",
    "    print(insta_dict['date'])\n",
    "    print()\n",
    "\n",
    "    ## like 정보 수집\n",
    "    try:\n",
    "        check=driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div[2]/section[2]/div/span/span')\n",
    "        \n",
    "    except:\n",
    "        try:\n",
    "            like=driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div[2]/section[2]/div/div/a/span')\n",
    "            insta_dict['like'].append(like)\n",
    "            \n",
    "        except:\n",
    "            id=[]\n",
    "            driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div[2]/section[2]/div/div[2]/a[2]').click()\n",
    "            while True:\n",
    "                last_height =driver.find_element_by_xpath('/html/body/div[7]/div/div/div[3]/div/div/div/div/div/div/span/a').location\n",
    "\n",
    "                c=driver.find_elements_by_xpath('/html/body/div[7]/div/div/div[3]/div/div/div/div/div/div/span/a')\n",
    "\n",
    "                for i in c:  \n",
    "                    if i.text not in id:\n",
    "                        id.append(i.text)     \n",
    "                    else:\n",
    "                        pass\n",
    "                \n",
    "                driver.find_element_by_css_selector('div._1XyCr').click()\n",
    "                driver.find_element_by_css_selector('body').send_keys(Keys.PAGE_DOWN)\n",
    "                driver.find_element_by_css_selector('body').send_keys(Keys.PAGE_DOWN)\n",
    "                driver.find_element_by_css_selector('body').send_keys(Keys.PAGE_DOWN)\n",
    "                time.sleep(1)\n",
    "                new_height =driver.find_element_by_xpath('/html/body/div[7]/div/div/div[3]/div/div/div/div/div/div/span/a').location\n",
    "\n",
    "                if last_height==new_height:\n",
    "                    driver.find_element_by_xpath('/html/body/div[7]/div/div/div[1]/div/div[2]/button').click()\n",
    "                    break\n",
    "\n",
    "            like=len(id)\n",
    "            insta_dict['like'].append(like)\n",
    "\n",
    "    ##text 정보수집\n",
    "    raw_info = driver.find_element_by_css_selector('div.C4VMK').text.split()\n",
    "    raw_info = raw_info[1:len(raw_info)-1]\n",
    "    text=[]\n",
    "    for i in raw_info:\n",
    "        if '#' in i:\n",
    "            pass\n",
    "        else:\n",
    "            text.append(i)\n",
    "    clean_text = ' '.join(text)\n",
    "    text.append(clean_text)\n",
    "    insta_dict['text'].append(text)\n",
    "\n",
    "\n",
    "\n",
    "    ##hashtag 수집\n",
    "    raw_tags = driver.find_elements_by_css_selector('a.xil3i')\n",
    "    hash_tag = []\n",
    "    for i in raw_tags:\n",
    "        hash_tag.append(i.text)\n",
    "    insta_dict['hashtag'].append(hash_tag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
